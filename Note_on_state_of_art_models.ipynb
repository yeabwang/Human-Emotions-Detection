{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/rsSksX/zVoTkMJagtdc1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeabwang/Human-Emotions-Detection/blob/main/Note_on_state_of_art_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frrl2MIc0Zag"
      },
      "outputs": [],
      "source": [
        "#AlexNet was a breakthrough in deep learning, winning the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012 and pioneering modern CNN architectures.\n",
        "\n",
        "# Architecture: 8 layers (5 convolutional + 3 fully connected).\n",
        "\n",
        "# Input Size: 227 × 227 × 3 (RGB images).\n",
        "\n",
        "# Convolutional Layers:\n",
        "#### Conv1: 96 filters, 11×11 kernel, stride 4, ReLU.\n",
        "#### Conv2: 256 filters, 5×5 kernel, stride 1, ReLU.\n",
        "#### Conv3: 384 filters, 3×3 kernel, stride 1, ReLU.\n",
        "#### Conv4: 384 filters, 3×3 kernel, stride 1, ReLU.\n",
        "#### Conv5: 256 filters, 3×3 kernel, stride 1, ReLU.\n",
        "\n",
        "# Max Pooling: After Conv1, Conv2, and Conv5 (3×3 kernel, stride 2).\n",
        "\n",
        "# Fully Connected Layers:\n",
        "#### FC6: 4096 neurons, ReLU.\n",
        "#### FC7: 4096 neurons, ReLU.\n",
        "#### FC8 (Output): 1000 neurons (ImageNet classes), Softmax.\n",
        "\n",
        "# Activation Function: ReLU (introduced to speed up training).\n",
        "# Normalization: Local Response Normalization (LRN) after Conv1 and Conv2.\n",
        "# Regularization: Dropout (0.5) in FC6 and FC7.\n",
        "# Optimization: Stochastic Gradient Descent (SGD) with momentum (0.9).\n",
        "# Batch Size: 128.\n",
        "# Weight Initialization: Gaussian distribution.\n",
        "# Data Augmentation: Cropping, flipping, and color jittering.\n",
        "# Training Dataset: ImageNet (1.2 million images, 1000 classes).\n",
        "# Parallel Training: Two GPUs used to split model layers for efficiency"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## VGG Model\n",
        "# Key Features:\n",
        "# Deep Network: 16 (VGG16) or 19 (VGG19) layers.\n",
        "# Uniform Kernel Size: Only 3×3 convolution layers to maintain consistency.\n",
        "# Increased Depth: More layers compared to AlexNet for hierarchical feature learning.\n",
        "# Regularization: Dropout (0.5) in fully connected layers.\n",
        "# Optimization: SGD with momentum (0.9), batch size = 256.\n",
        "# Weight Initialization: Pretrained on ImageNet, useful for transfer learning.\n",
        "# Data Augmentation: Cropping, flipping, and color jittering\n",
        "# VGG16 and VGG19 are the most common variants. #the main difference here is the number of convulational neurons used vgg16 used 13 convulational neurons and the vgg 19 uses the 16 convulational neurons\n",
        "# Stacked small convolutional filters (3×3 kernel, stride 1, padding 1) for deeper representations.\n",
        "# Uses 2×2 max pooling (stride 2) after every block for downsampling.\n",
        "\n",
        "\n",
        "# Layers - Vgg16\n",
        "# Input Size: 224 × 224 × 3 (RGB images).\n",
        "\n",
        "# Conv Layers:\n",
        "#### Block 1: 2 × (64 filters, 3×3, ReLU) → Max Pooling\n",
        "#### Block 2: 2 × (128 filters, 3×3, ReLU) → Max Pooling\n",
        "#### Block 3: 3 × (256 filters, 3×3, ReLU) → Max Pooling\n",
        "#### Block 4: 3 × (512 filters, 3×3, ReLU) → Max Pooling\n",
        "#### Block 5: 3 × (512 filters, 3×3, ReLU) → Max Pooling\n",
        "\n",
        "# Fully Connected Layers:\n",
        "#### FC6: 4096 neurons, ReLU\n",
        "#### FC7: 4096 neurons, ReLU\n",
        "#### FC8 (Output): 1000 neurons (Softmax for classification)\n",
        "\n"
      ],
      "metadata": {
        "id": "Wz7UjWm053uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RESNET MODEL\n",
        "\n",
        "# ResNet introduced residual learning to address the vanishing gradient problem, allowing for extremely deep networks.\n",
        "\n",
        "# Key Features:\n",
        "#### Deep Architecture: Can scale up to ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152.\n",
        "#### Residual Connections (Skip Connections):\n",
        "####### Instead of directly learning H(x), it learns F(x) = H(x) - x, making optimization easier.\n",
        "#### Helps gradients flow smoothly during backpropagation.\n",
        "#### Batch Normalization: Used after every convolution to stabilize training.\n",
        "#### ReLU Activation: Applied after each convolutional layer.\n",
        "\n",
        "# ResNet-18 Layer-by-Layer Breakdown\n",
        "# Here is the detailed layer-wise breakdown for ResNet-18:\n",
        "\n",
        "# Conv1 (Initial Convolutional Layer):\n",
        "\n",
        "# Operation: 7×7 Convolution, 64 filters, stride 2\n",
        "# Output Size: 112 × 112 × 64\n",
        "# MaxPool:\n",
        "\n",
        "# Operation: 3×3 Max Pooling, stride 2\n",
        "# Output Size: 56 × 56 × 64\n",
        "# Conv2_x (Residual Block 1 and 2):\n",
        "\n",
        "# Operation: 2 × Basic Residual Blocks (each with 2x 3×3 convolutions, 64 filters)\n",
        "# Output Size: 56 × 56 × 64\n",
        "# Conv3_x (Residual Block 3 and 4):\n",
        "\n",
        "# Operation: 2 × Basic Residual Blocks (each with 2x 3×3 convolutions, 128 filters), stride 2\n",
        "# Output Size: 28 × 28 × 128\n",
        "# Conv4_x (Residual Block 5 and 6):\n",
        "\n",
        "# Operation: 2 × Basic Residual Blocks (each with 2x 3×3 convolutions, 256 filters), stride 2\n",
        "# Output Size: 14 × 14 × 256\n",
        "# Conv5_x (Residual Block 7 and 8):\n",
        "\n",
        "# Operation: 2 × Basic Residual Blocks (each with 2x 3×3 convolutions, 512 filters), stride 2\n",
        "# Output Size: 7 × 7 × 512\n",
        "# AvgPool (Global Average Pooling):\n",
        "\n",
        "# Operation: Global Average Pooling\n",
        "# Output Size: 1 × 1 × 512\n",
        "# Fully Connected (FC):\n",
        "\n",
        "# Operation: Fully Connected layer (512 → 1000 classes)\n",
        "# Output Size: 1 × 1 × 1000 (classification result)\n",
        "\n",
        "\n",
        "## So we can see ResNet as a collection of shallow layers with a condition of skipping layers which their cumulative is zero.\n",
        "## Firstly this will help the model avoid vanishing gradient.\n",
        "## Seconly it performs well since it acts like a collection of various shallow layers which the model choose its path based on the conditions.\n",
        "\n"
      ],
      "metadata": {
        "id": "bgyAriga_yfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Covariate Shift and Batch Normalization\n",
        "\n",
        "# # Covariate Shift\n",
        "# # Covariate Shift refers to a situation where the distribution of the input data changes between training and testing phases, but the conditional distribution of the output given the input remains the same. In simpler terms, it happens when the model is trained on data from one distribution, but when deployed, it encounters data from a different distribution, which can hurt model performance.\n",
        "\n",
        "# # Batch Normalization (BatchNorm)\n",
        "# # Batch Normalization is a technique introduced to address internal covariate shift during the training of deep neural networks. It normalizes the activations of each layer by scaling and shifting them, ensuring that the distribution of inputs to each layer remains stable throughout training.\n",
        "\n",
        "# In 2D Global Average Pooling, the pooling operation averages over all spatial dimensions (height and width) for each feature map (channel) of the input.\n",
        "# Instead of using traditional pooling methods like max pooling (which extracts the maximum value), global average pooling computes the average value of each feature map over its entire spatial area.\n"
      ],
      "metadata": {
        "id": "8bw9XadsTgwL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}